{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fejML3tCfv"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_latent_vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nTYnTqOPtCfy"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "\n",
    "**Module 1: Python Preliminaries**\n",
    "\n",
    "- Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "- For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ssJkCaz-DRuG"
   },
   "source": [
    "# Module 7 Material\n",
    "\n",
    "- Part 7.1: Introduction to GANs for Image and Data Generation [[Video]](https://www.youtube.com/watch?v=hZw-AjbdN5k&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_1_gan_intro.ipynb)\n",
    "- Part 7.2: Train StyleGAN3 with your Own Images [[Video]](https://www.youtube.com/watch?v=R546LYsQk5M&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_2_train_gan.ipynb)\n",
    "- **Part 7.3: Exploring the StyleGAN Latent Vector** [[Video]](https://www.youtube.com/watch?v=goQzp8QSb2s&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_3_latent_vector.ipynb)\n",
    "- Part 7.4: GANs to Enhance Old Photographs Deoldify [[Video]](https://www.youtube.com/watch?v=0OTd5GlHRx4&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_4_deoldify.ipynb)\n",
    "- Part 7.5: GANs for Tabular Synthetic Data Generation [[Video]](https://www.youtube.com/watch?v=yujdA46HKwA&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_5_tabular_synthetic.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "An52HQqsD1zD"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fo-DMTVDxaG",
    "outputId": "12052b93-1857-45d9-d7a3-7f8234d6c71b"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LPud7uV-EGUD"
   },
   "source": [
    "# Part 7.3: Exploring the StyleGAN Latent Vector\n",
    "\n",
    "StyleGAN seeds, such as 3000, are only random number seeds used to generate much longer 512-length latent vectors, which create the GAN image. If you make a small change to the seed, for example, change 3000 to 3001, StyleGAN will create an entirely different picture. However, if you make a small change to a few latent vector values, the image will only change slightly. In this part, we will see how we can fine-tune the latent vector to control, to some degree, the resulting GAN image appearance.\n",
    "\n",
    "## Installing Needed Software\n",
    "\n",
    "We begin by installing StyleGAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNAuO-EMHGD_",
    "outputId": "e8211b29-5a61-46ed-d336-8e2e728e56c2"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "!git clone https://github.com/NVlabs/stylegan3.git\n",
    "!pip install ninja"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1dSyqtjWHGzH"
   },
   "source": [
    "We will use the same functions introduced in the previous part to generate GAN seeds and images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tB0TryzptCf_"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/content/stylegan3\")\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import torch\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "\n",
    "def seed2vec(G, seed):\n",
    "    return np.random.RandomState(seed).randn(1, G.z_dim)\n",
    "\n",
    "\n",
    "def display_image(image):\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_image(G, z, truncation_psi):\n",
    "    # Render images for dlatents initialized from random seeds.\n",
    "    Gs_kwargs = {\n",
    "        \"output_transform\": dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
    "        \"randomize_noise\": False,\n",
    "    }\n",
    "    if truncation_psi is not None:\n",
    "        Gs_kwargs[\"truncation_psi\"] = truncation_psi\n",
    "\n",
    "    label = np.zeros([1] + G.input_shapes[1][1:])\n",
    "    # [minibatch, height, width, channel]\n",
    "    images = G.run(z, label, **G_kwargs)\n",
    "    return images[0]\n",
    "\n",
    "\n",
    "def get_label(G, device, class_idx):\n",
    "    label = torch.zeros([1, G.c_dim], device=device)\n",
    "    if G.c_dim != 0:\n",
    "        if class_idx is None:\n",
    "            ctx.fail(\n",
    "                \"Must specify class label with --class\"\n",
    "                \"when using a conditional network\"\n",
    "            )\n",
    "        label[:, class_idx] = 1\n",
    "    else:\n",
    "        if class_idx is not None:\n",
    "            print(\n",
    "                \"warn: --class=lbl ignored when running \" \"on an unconditional network\"\n",
    "            )\n",
    "    return label\n",
    "\n",
    "\n",
    "def generate_image(\n",
    "    device, G, z, truncation_psi=1.0, noise_mode=\"const\", class_idx=None\n",
    "):\n",
    "    z = torch.from_numpy(z).to(device)\n",
    "    label = get_label(G, device, class_idx)\n",
    "    img = G(z, label, truncation_psi=truncation_psi, noise_mode=noise_mode)\n",
    "    img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n",
    "    return PIL.Image.fromarray(img[0].cpu().numpy(), \"RGB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "l0II9vb67nMg"
   },
   "source": [
    "Next, we load the NVIDIA FFHQ (faces) GAN. We could use any StyleGAN pretrained GAN network here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIrKjvFcOxLY",
    "outputId": "ceab6379-0cb1-47d9-b1ac-6801b39cf163"
   },
   "outputs": [],
   "source": [
    "# HIDE CODE\n",
    "\n",
    "URL = (\n",
    "    \"https://api.ngc.nvidia.com/v2/models/nvidia/research/\"\n",
    "    \"stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    ")\n",
    "\n",
    "print('Loading networks from \"%s\"...' % URL)\n",
    "device = torch.device(\"cuda\")\n",
    "with dnnlib.util.open_url(URL) as fp:\n",
    "    G = legacy.load_network_pkl(fp)[\"G_ema\"].requires_grad_(False).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3B7Z2wpy9H5f"
   },
   "source": [
    "## Generate and View GANS from Seeds\n",
    "\n",
    "We will begin by generating a few seeds to evaluate potential starting points for our fine-tuning. Try out different seeds ranges until you have a seed that looks close to what you wish to fine-tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "BVCBuYf5U3_Z",
    "outputId": "add2cb48-ce7b-484a-d4c8-ad2602c57c80"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT 1\n",
    "# Choose your own starting and ending seed.\n",
    "SEED_FROM = 4020\n",
    "SEED_TO = 4023\n",
    "\n",
    "# Generate the images for the seeds.\n",
    "for i in range(SEED_FROM, SEED_TO):\n",
    "    print(f\"Seed {i}\")\n",
    "    z = seed2vec(G, i)\n",
    "    img = generate_image(device, G, z)\n",
    "    display_image(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zwrF63i5yfLj"
   },
   "source": [
    "## Fine-tune an Image\n",
    "\n",
    "If you find a seed you like, you can fine-tune it by directly adjusting the latent vector. First, choose the seed to fine-tune.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GG26Mj_RlaMK"
   },
   "outputs": [],
   "source": [
    "START_SEED = 4022\n",
    "\n",
    "current = seed2vec(G, START_SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "E8Q4m9zW9df7"
   },
   "source": [
    "Next, generate and display the current vector. You will return to this point for each iteration of the finetuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "Hll7iwGzWKuM",
    "outputId": "0ec7a2d4-d44a-4435-f67a-2aaafcc50494"
   },
   "outputs": [],
   "source": [
    "img = generate_image(device, G, current)\n",
    "\n",
    "SCALE = 0.5\n",
    "display_image(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gsN_IlZ69t-Q"
   },
   "source": [
    "Choose an explore size; this is the number of different potential images chosen by moving in 10 different directions. Run this code once and then again anytime you wish to change the ten directions you are exploring. You might change the ten directions if you are no longer seeing improvements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGM4JHUPQulD"
   },
   "outputs": [],
   "source": [
    "EXPLORE_SIZE = 25\n",
    "\n",
    "explore = []\n",
    "for i in range(EXPLORE_SIZE):\n",
    "    explore.append(np.random.rand(1, 512) - 0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "d_2Tol2U61AW"
   },
   "source": [
    "Each image displayed from running this code shows a potential direction that we can move in the latent vector. Choose one image that you like and change MOVE_DIRECTION to indicate this decision. Once you rerun the code, the code will give you a new set of potential directions. Continue this process until you have a latent vector that you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9L6ol1swSogS",
    "outputId": "8b4a2bb6-857c-4ab6-957d-fed752b3a89c"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT 1\n",
    "# Choose the direction to move.  Choose -1 for the initial iteration.\n",
    "MOVE_DIRECTION = -1\n",
    "SCALE = 0.5\n",
    "\n",
    "if MOVE_DIRECTION >= 0:\n",
    "    current = current + explore[MOVE_DIRECTION]\n",
    "\n",
    "for i, mv in enumerate(explore):\n",
    "    print(f\"Direction {i}\")\n",
    "    z = current + mv\n",
    "    img = generate_image(device, G, z)\n",
    "    display_image(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of t81_558_class_07_3_latent_vector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
