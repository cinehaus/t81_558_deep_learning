{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LSIM-PITWYFa"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_05_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YDTXd8-Lmp8Q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "\n",
    "**Module 13: Advanced/Other Topics**\n",
    "\n",
    "- Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "- For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ncNrAEpzmp8S"
   },
   "source": [
    "# Module 13 Video Material\n",
    "\n",
    "- Part 13.1: Flask and Deep Learning Web Services [[Video]](https://www.youtube.com/watch?v=H73m9XvKHug&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_01_flask.ipynb)\n",
    "- Part 13.2: Interrupting and Continuing Training [[Video]](https://www.youtube.com/watch?v=kaQCdv46OBA&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_02_checkpoint.ipynb)\n",
    "- Part 13.3: Using a Keras Deep Neural Network with a Web Application [[Video]](https://www.youtube.com/watch?v=OBbw0e-UroI&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_03_web.ipynb)\n",
    "- Part 13.4: When to Retrain Your Neural Network [[Video]](https://www.youtube.com/watch?v=K2Tjdx_1v9g&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_04_retrain.ipynb)\n",
    "- **Part 13.5: Tensor Processing Units (TPUs)** [[Video]](https://www.youtube.com/watch?v=Ygyf3NUqvSc&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_13_05_tpu.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lux_6KOXMU94"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU9UhAxTmp8S",
    "outputId": "8a0287ac-a84c-41c0-c9c1-a8a51600370d"
   },
   "outputs": [],
   "source": [
    "# Detect Colab if present\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TX_m2PyCWn3e"
   },
   "source": [
    "To use Tensor Processing Units (TPUs), you must grant access to Google Cloud Platform (GCP) drives. If this access is not successfully, you will likely see this error:\n",
    "\n",
    "```\n",
    "InvalidArgumentError: Unable to parse tensor proto\n",
    "```\n",
    "\n",
    "From Google CoLab, issue the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xomyq-3zQAaz"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q09yMGGcmp9N"
   },
   "source": [
    "# Part 13.5: Tensor Processing Units (TPUs)\n",
    "\n",
    "This book focuses primarily on NVIDIA Graphics Processing Units (GPUs) for deep learning acceleration. NVIDIA GPUs are not the only option for deep learning acceleration. TensorFlow continues to gain additional support for AMD and Intel GPUs. TPUs are also available from Google cloud platforms to accelerate deep learning. The focus of this book and course is on NVIDIA GPUs because of their wide availability on both local and cloud systems.\n",
    "\n",
    "Though this book focuses on NVIDIA GPUs, we will briefly examine Google Tensor Processing Units (TPUs). These devices are an AI accelerator Application-Specific Integrated Circuit (ASIC) developed by Google. They were designed specifically for neural network machine learning, mainly using Google's TensorFlow software. Google began using TPUs internally in 2015 and in 2018 made them available for third-party use, both as part of its cloud infrastructure and by offering a smaller version of the chip for sale.\n",
    "\n",
    "The full use of a TPU is a complex topic that I only introduced in this part. Supporting TPUs is slightly more complicated than GPUs because specialized coding is needed. Changes are rarely required to adapt CPU code to GPU for most relatively simple mainstream GPU tasks in TensorFlow. I will cover the mild code changes needed to utilize in this part.\n",
    "\n",
    "We will create a regression neural network to count paper clips in this part. I demonstrated this dataset and task several times previously in this book. This part focuses on the utilization of TPUs and not the creation of neural networks. I covered the design of computer vision previously in this book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8ixjIi5p8Uy",
    "outputId": "f82eed1a-b2d1-4d84-edf0-13c7b3650e2e"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://github.com/jeffheaton/data-mirror/\"\n",
    "DOWNLOAD_SOURCE = URL+\"releases/download/v1/paperclips.zip\"\n",
    "DOWNLOAD_NAME = DOWNLOAD_SOURCE[DOWNLOAD_SOURCE.rfind('/')+1:]\n",
    "\n",
    "if COLAB:\n",
    "  PATH = \"/content\"\n",
    "else:\n",
    "  # I used this locally on my machine, you may need different\n",
    "  PATH = \"/Users/jeff/temp\"\n",
    "\n",
    "EXTRACT_TARGET = os.path.join(PATH,\"clips\")\n",
    "SOURCE = os.path.join(EXTRACT_TARGET, \"paperclips\")\n",
    "\n",
    "# Download paperclip data\n",
    "!wget -O {os.path.join(PATH,DOWNLOAD_NAME)} {DOWNLOAD_SOURCE}\n",
    "!mkdir -p {SOURCE}\n",
    "!mkdir -p {TARGET}\n",
    "!mkdir -p {EXTRACT_TARGET}\n",
    "!unzip -o -j -d {SOURCE} {os.path.join(PATH, DOWNLOAD_NAME)} >/dev/null\n",
    "\n",
    "# Add filenames\n",
    "df_train = pd.read_csv(os.path.join(SOURCE, \"train.csv\"))\n",
    "df_train['filename'] = \"clips-\" + df_train.id.astype(str) + \".jpg\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pw_ysSVRiZcP"
   },
   "source": [
    "## Preparing Data for TPUs\n",
    "\n",
    "To present the paperclips dataset to the TPU, we will convert the images to a Keras Dataset. Because we will load the entire dataset to RAM, we will only utilize the first 1,000 images. We previously loaded the labels from the **train.csv** file. The following code loads these images and converts them to a Keras dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RY4NU-vz_Eis",
    "outputId": "586c3d29-080d-4d38-cbe7-3b25bac78963"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "import glob, os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "IMG_SHAPE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Resize each image and convert the 0-255 ranged RGB values to 0-1 range.\n",
    "def load_images(files, img_shape):\n",
    "    cnt = len(files)\n",
    "    x = np.zeros((cnt,) + img_shape + (3,), dtype=np.float32)\n",
    "    i = 0\n",
    "    for file in tqdm.tqdm(files):\n",
    "        img = Image.open(file)\n",
    "        img = img.resize(img_shape)\n",
    "        img = np.array(img)\n",
    "        img = img / 255\n",
    "        x[i, :, :, :] = img\n",
    "        i += 1\n",
    "    return x\n",
    "\n",
    "\n",
    "# Process training data\n",
    "df_train = pd.read_csv(os.path.join(SOURCE, \"train.csv\"))\n",
    "df_train[\"filename\"] = \"clips-\" + df_train.id.astype(str) + \".jpg\"\n",
    "\n",
    "# Use only the first 1000 images\n",
    "df_train = df_train[0:1000]\n",
    "\n",
    "# Load images\n",
    "images = [os.path.join(SOURCE, x) for x in df_train.filename]\n",
    "x = load_images(images, IMG_SHAPE)\n",
    "y = df_train.clip_count.values\n",
    "\n",
    "# Convert to dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ig6mQ4tBlDsp"
   },
   "source": [
    "TPUs are typically Cloud TPU workers, different from the local process running the user's Python program. Thus, it would be best to do some initialization work to connect to the remote cluster and initialize the TPUs. The TPU argument to **tf.distribute.cluster_resolver**. **TPUClusterResolver** is a unique address just for Colab. If you are running your code on Google Compute Engine (GCE), you should instead pass in the name of your Cloud TPU. The following code performs this initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7O04z13LV0Dp",
    "outputId": "f405a27a-562a-4441-ce9c-6cf752686025"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "    print(\"Device:\", tpu.master())\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8rVZJBMIgqJq"
   },
   "source": [
    "We will now use a ResNet neural network as a basis for our neural network. We begin by loading, from Keras, the ResNet50 network. We will redefine both the input shape and output of the ResNet model, so we will not transfer the weights. Since we redefine the input, the weights are of minimal value. We specify **include_top** as False because we will change the input resolution. We also specify **weights** as false because we must retrain the network after changing the top input layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MJpmLyhtahJ",
    "outputId": "f92c5133-c710-498f-df5a-1614e7be7cbe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=IMG_SHAPE + (3,))\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False, weights=None, input_tensor=input_tensor, input_shape=None\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=Dense(1)(x))\n",
    "    return model\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mean_squared_error\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[RootMeanSquaredError(name=\"rmse\")],\n",
    "    )\n",
    "\n",
    "    history = model.fit(dataset, epochs=100, steps_per_epoch=32, verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9v9hQ59MUwI2"
   },
   "source": [
    "You might receive the following error while fitting the neural network.\n",
    "\n",
    "```\n",
    "InvalidArgumentError: Unable to parse tensor proto\n",
    "```\n",
    "\n",
    "If you do receive this error, it is likely because you are missing proper authentication to access Google Drive to store your datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "base-tpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
